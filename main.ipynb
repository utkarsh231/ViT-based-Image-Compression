{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Run On Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# First cell - Clone repository\n",
    "!git clone https://github.com/utkarsh231/ViT-based-Image-Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd ViT-based-Image-Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Second cell - Install dependencies\n",
    "# If this breaks - restart and dont run this again\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# Set custom path before downloading\n",
    "os.environ[\"KAGGLEHUB_DIR\"] = \"/content/ViT-based-Image-Compression\"\n",
    "\n",
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"crawford/cat-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fourth cell - Prepare dataset\n",
    "!python prepare_cat_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from IPython.display import Image, display\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "from inference import run_inference\n",
    "from tic_vit_encoder import ViTCompressor\n",
    "from config import CompressionConfig\n",
    "from torch.serialization import add_safe_globals\n",
    "\n",
    "# Add CompressionConfig to safe globals for checkpoint loading\n",
    "add_safe_globals([CompressionConfig])\n",
    "\n",
    "# 1. Set image path (using your specific path)\n",
    "image_path = \"/content/ViT-based-Image-Compression/data/val/00000001_000.jpg\"\n",
    "print(f\"Using image: {image_path}\")\n",
    "\n",
    "# 2. Load the model\n",
    "print(\"\\nLoading model...\")\n",
    "config = CompressionConfig()\n",
    "model = ViTCompressor(\n",
    "    img_size=config.img_size,\n",
    "    patch_size=config.patch_size,\n",
    "    embed_dim=config.embed_dim\n",
    ")\n",
    "\n",
    "# 3. Load checkpoint (replace with your checkpoint path)\n",
    "checkpoint_path = '/content/ViT-based-Image-Compression/checkpoints/checkpoint_epoch_49.pt'\n",
    "print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "\n",
    "# Load checkpoint with weights_only=False to handle the config\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cuda', weights_only=False)\n",
    "if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)  # Direct state dict\n",
    "\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "# 4. Run inference\n",
    "print(\"\\nRunning inference...\")\n",
    "output_dir = '/content/drive/MyDrive/transformer_compression/outputs/single_test'\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "# Modified inference function to handle device\n",
    "def run_inference_cuda(model, image_path, output_dir, img_size=256):\n",
    "    \"\"\"Run model inference on a single image with CUDA support.\"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load and process image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = PILImage.open(image_path).convert('RGB')\n",
    "    x = transform(image).unsqueeze(0).cuda()  # Move input to CUDA\n",
    "    \n",
    "    # Run model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_hat, likelihoods = model(x)\n",
    "    \n",
    "    # Move tensors back to CPU for saving\n",
    "    x = x.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = torch.mean((x - x_hat) ** 2)\n",
    "    psnr = 10 * torch.log10(1.0 / mse)\n",
    "    bpp = -torch.log2(likelihoods).mean() / (img_size * img_size)\n",
    "    \n",
    "    # Save original and reconstructed images\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "    \n",
    "    # Denormalize and save original\n",
    "    x_denorm = x * std + mean\n",
    "    x_denorm = torch.clamp(x_denorm, 0, 1)\n",
    "    x_img = (x_denorm.squeeze(0).permute(1, 2, 0).numpy() * 255).astype('uint8')\n",
    "    PILImage.fromarray(x_img).save(os.path.join(output_dir, 'original.png'))\n",
    "    \n",
    "    # Denormalize and save reconstructed\n",
    "    x_hat_denorm = x_hat * std + mean\n",
    "    x_hat_denorm = torch.clamp(x_hat_denorm, 0, 1)\n",
    "    x_hat_img = (x_hat_denorm.squeeze(0).permute(1, 2, 0).numpy() * 255).astype('uint8')\n",
    "    PILImage.fromarray(x_hat_img).save(os.path.join(output_dir, 'reconstructed.png'))\n",
    "    \n",
    "    # Plot and save metrics\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(x_img)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(x_hat_img)\n",
    "    plt.title(f'Reconstructed\\nPSNR: {psnr:.2f} dB, BPP: {bpp:.4f}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.savefig(os.path.join(output_dir, 'comparison.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Run the modified inference\n",
    "run_inference_cuda(model, image_path, output_dir, img_size=config.img_size)\n",
    "\n",
    "# 5. Display results\n",
    "print(\"\\nResults saved in:\", output_dir)\n",
    "display(Image(filename=os.path.join(output_dir, 'comparison.png')))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
